{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of Classes = 2\n",
      "No.of Features = 4\n"
     ]
    }
   ],
   "source": [
    "#reading and shuffling data\n",
    "read = np.loadtxt('dataset_LP_1.txt',delimiter=',',skiprows=1)\n",
    "np.random.shuffle(read)\n",
    "\n",
    "#classifying as features and class\n",
    "labels = read[:,-1]\n",
    "data = read[:,0:len(read[0])-1]\n",
    "\n",
    "nclasses = len(np.unique(labels))\n",
    "nfeatures = len(data[0])\n",
    "\n",
    "print(\"No.of Classes = {}\".format(nclasses))\n",
    "print(\"No.of Features = {}\".format(nfeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.5449   -10.1498     9.6152    -1.2332  ]\n",
      " [ -2.4561    -4.5566     6.4534    -0.056479]\n",
      " [  1.8216    -6.4748     8.0514    -0.41855 ]\n",
      " ...\n",
      " [  1.4578    -0.08485    4.1785     0.59136 ]\n",
      " [ -1.005      0.084831  -0.2462     0.45688 ]\n",
      " [  0.74841    7.2756     1.1504    -0.5388  ]]\n"
     ]
    }
   ],
   "source": [
    "#creating 70:30 train-test splits\n",
    "train_size = int(len(data)*0.7)\n",
    "\n",
    "df_train = data[0:train_size]\n",
    "train_class = labels[0:train_size]\n",
    "train_class1 = np.reshape(train_class,(len(train_class),1))\n",
    "\n",
    "df_test  = data[train_size:]\n",
    "test_class = labels[train_size:]\n",
    "test_class1 = np.reshape(test_class,(len(test_class),1))\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = df_train.shape\n",
    "mt, nt = df_test.shape\n",
    "lr = 0.01\n",
    "w = np.zeros((nfeatures,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicts the classification of the point\n",
    "def predict(data, weights, bias):\n",
    "    gx = np.dot(data,weights)+bias\n",
    "    if(gx>=0):\n",
    "         return 1\n",
    "   \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training data = 98.43587069864442%\n",
      "Weight vector is [[-1.5988016 ]\n",
      " [-0.93816236]\n",
      " [-0.98104361]\n",
      " [-0.19807819]]\n"
     ]
    }
   ],
   "source": [
    "#fitting w\n",
    "flag = 1\n",
    "bias = 0.0\n",
    "epochs = 1000\n",
    "#no.of iterations\n",
    "for e in range(epochs):    \n",
    "    count = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        xi = np.array(df_train[i])\n",
    "        xi = np.expand_dims(xi, axis=0)\n",
    "\n",
    "        #predicted class label\n",
    "        hx = predict(xi,w,bias)\n",
    "        #error = expectd - predicted\n",
    "        delta = (train_class1[i] - hx)\n",
    "        #if error is non zero update the weight vector (Stochastic gradient)\n",
    "        if(delta != 0):\n",
    "            w = w + lr*delta*(xi.T)\n",
    "            bias = bias + lr * delta\n",
    "        else:\n",
    "            count += 1\n",
    "        #accuracy   \n",
    "        acc = count/m\n",
    "        if acc==1.0:\n",
    "            flag = 0;\n",
    "            break\n",
    "    if(flag == 0):\n",
    "        break\n",
    "\n",
    "print('Accuracy of training data = {}%'.format(acc*100))\n",
    "print('Weight vector is {}'.format(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting for the test data\n",
    "y_testp = []\n",
    "for row in df_test:\n",
    "    xi = np.array(row)\n",
    "    xi = np.expand_dims(xi, axis=0)\n",
    "    y_testp.append(predict(xi,w,bias))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test data =  98.05825242718447\n"
     ]
    }
   ],
   "source": [
    "#accuracy of test data\n",
    "count = 0\n",
    "#calculate no.of correctly classified data\n",
    "for i in range(mt):\n",
    "    if y_testp[i] == test_class1[i]:\n",
    "        count = count + 1\n",
    "accuracy = (count/mt)*100\n",
    "print(\"accuracy on test data = \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
