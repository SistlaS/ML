{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpmath import mpf, mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.dps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data\n",
    "path = \"dataset_NB.txt\"\n",
    "data = []\n",
    "with open(path) as f:\n",
    "    data.append(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data[0]\n",
    "len(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenising the given data to rid them of punctuation marks\n",
    "def token(data):\n",
    "    \n",
    "    data_n = []\n",
    "    \n",
    "    l = len(data)\n",
    "    \n",
    "    for i in range(l):\n",
    "        lis = []\n",
    "        string = data1[i].split()\n",
    "        yi = [string[-1]]\n",
    "        slen = len(string)\n",
    "        for j in range(slen - 1):\n",
    "            s1 = \"\"\n",
    "            if string[j] not in punc:\n",
    "                for e in string[j]:\n",
    "                    if e not in punc:\n",
    "                        s1 = s1 + e\n",
    "            lis.append(s1)\n",
    "                                              \n",
    "        data_n.append([lis, yi])\n",
    "        \n",
    "    data_np = np.array(data_n)\n",
    "        \n",
    "    return data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = token(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_w(data_tr, alpha):\n",
    "    #dictionary of the words\n",
    "    # key : word\n",
    "    #value : [freq_in_nonspam, freq_inspam, tot_count]\n",
    "    dic_w = {}\n",
    "    ld = len(data_tr)\n",
    "    #total words\n",
    "    N = 0\n",
    "    Y = 0\n",
    "    No = 0\n",
    "    #number of spam and nonspam words\n",
    "    spam = 0\n",
    "    nspam = 0\n",
    "    for i in range(ld):\n",
    "        data = data_tr[i]\n",
    "        for a in data:\n",
    "            yl = a[1][0]\n",
    "            if yl == \"0\":\n",
    "                nspam = nspam + 1\n",
    "            elif yl == \"1\":\n",
    "                spam = spam + 1\n",
    "            wl = a[0]\n",
    "            for word in wl:\n",
    "                N = N + 1\n",
    "                if word not in dic_w.keys():\n",
    "                    if yl == \"0\":\n",
    "                        dic_w[word] = [1, 0, 1]\n",
    "                    elif yl == \"1\":\n",
    "                        dic_w[word] = [0, 1, 1]\n",
    "                else:\n",
    "                    #computing frequencies of the words\n",
    "                    if yl == \"0\":\n",
    "                        dic_w[word][0] = dic_w[word][0] + 1\n",
    "                    elif yl == \"1\":\n",
    "                        dic_w[word][1] = dic_w[word][1] + 1\n",
    "                    dic_w[word][2] = dic_w[word][2] + 1\n",
    "    \n",
    "    #total frequency of spam and nonspam words               \n",
    "    for word in dic_w.keys():\n",
    "        No = No + dic_w[word][0]\n",
    "        Y = Y + dic_w[word][1]\n",
    "    \n",
    "    #probabilties of word being nonspam, spam and total probability\n",
    "    for word in dic_w.keys():\n",
    "        dic_w[word][0] = (dic_w[word][0] + alpha)/(No + len(dic_w)*alpha)\n",
    "        dic_w[word][1] = (dic_w[word][1] + alpha)/(Y + len(dic_w)*alpha)\n",
    "        dic_w[word][2] = (dic_w[word][2] + alpha)/(N + len(dic_w)*alpha)\n",
    "    \n",
    "    lisp = [dic_w, spam, nspam]\n",
    "\n",
    "    return lisp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_val_fit(data_trial, k, alpha):\n",
    "    #grouping the data into k folds\n",
    "    # alpha is the laplace smoothening rate\n",
    "#     np.random.shuffle(data_trial)\n",
    "    data_g = np.array_split(data_trial, k)\n",
    "    #accuracy for training data and testing data\n",
    "    nb_accuracy = {}\n",
    "    nbtr_accuracy = {}\n",
    "    tr_acc = {}\n",
    "    for i in range(k):\n",
    "        data_tes = data_g[i]\n",
    "        data_tr = []\n",
    "        lenm = 0\n",
    "        for j in range(k):\n",
    "            if j!=i:\n",
    "                data_tr.append(data_g[j])\n",
    "                lenm = lenm + len(data_g[j])\n",
    "        #computing the dictonary for each fold\n",
    "        lisp = dict_w(data_tr, alpha)\n",
    "        dicti_w = lisp[0]\n",
    "        spam = lisp[1]\n",
    "        nspam = lisp[2]\n",
    "        #probabilty of spam and nonspam\n",
    "        #class probability\n",
    "        P0 = mpf(nspam)/(lenm)\n",
    "        P1 = mpf(spam)/(lenm)\n",
    "        \n",
    "        count = 0\n",
    "        count1 = 0\n",
    "        nt = 0\n",
    "        countd = 0\n",
    "        for d in data_tr: \n",
    "            \n",
    "            for ar1 in d:\n",
    "                countd = countd + 1\n",
    "                ytrue = float(ar1[1][0])\n",
    "                wlt = ar1[0]\n",
    "                #probability of word given its spam/nonspam\n",
    "                #prior probability\n",
    "                Pw0 = 1\n",
    "                Pw1 = 1\n",
    "                Pw = 1\n",
    "                for word in wlt:\n",
    "                    if word in dicti_w.keys():\n",
    "                        lisw = dicti_w[word]\n",
    "                        Pw0 = Pw0*mpf(lisw[0])\n",
    "                        Pw1 = Pw1*mpf(lisw[1])\n",
    "                        Pw = Pw*mpf(lisw[2])\n",
    "                    else:\n",
    "                        #laplace smoothening\n",
    "                        Pw0 = Pw0*(alpha/(alpha*len(dicti_w)))\n",
    "                        Pw1 = Pw1*(alpha/(alpha*len(dicti_w)))\n",
    "                        Pw = Pw*(alpha/(alpha*len(dicti_w)))\n",
    "                #probability that the word is spam/nonspam\n",
    "                #posterior probabilty\n",
    "                Py0 = (mpf(Pw0)*mpf(P0))/mpf(Pw)\n",
    "                Py1 = (mpf(Pw1)*mpf(P1))/mpf(Pw)\n",
    "                py0 = mpf(Py0)/(mpf(Py0) + mpf(Py1))\n",
    "                py1 = mpf(Py1)/(mpf(Py0) + mpf(Py1))\n",
    "                \n",
    "                #prediction \n",
    "                if py0>py1:\n",
    "                    ypred = float(0)\n",
    "                elif py1>=py0:\n",
    "                    ypred = float(1)\n",
    "                if ypred == ytrue:\n",
    "                    count1 = count1 + 1\n",
    "                    \n",
    "            accuracy = (count1/countd)*100\n",
    "            stringi = \"train\" + str(nt)\n",
    "            nbtr_accuracy[stringi] = accuracy \n",
    "            nt = nt + 1\n",
    "        s = \"train\" + str(i)\n",
    "        av = sum(nbtr_accuracy.values()) / len(nbtr_accuracy)\n",
    "        tr_acc[s] = av\n",
    "       \n",
    "        \n",
    "        for ar in data_tes:   \n",
    "\n",
    "            ytrue = float(ar[1][0])\n",
    "            wlt = ar[0]\n",
    "            #probability of word given its spam/nonspam\n",
    "            #prior probability\n",
    "            Pw0 = 1\n",
    "            Pw1 = 1\n",
    "            Pw = 1\n",
    "            for word in wlt:\n",
    "                if word in dicti_w.keys():\n",
    "                    lisw = dicti_w[word]\n",
    "                    Pw0 = Pw0*mpf(lisw[0])\n",
    "                    Pw1 = Pw1*mpf(lisw[1])\n",
    "                    Pw = Pw*mpf(lisw[2])\n",
    "                else:\n",
    "                    #laplace smoothening\n",
    "                    Pw0 = Pw0*(alpha/(alpha*len(dicti_w)))\n",
    "                    Pw1 = Pw1*(alpha/(alpha*len(dicti_w)))\n",
    "                    Pw = Pw*(alpha/(alpha*len(dicti_w)))\n",
    "            #probability that the word is spam/nonspam\n",
    "            #posterior probabilty       \n",
    "            Py0 = (mpf(Pw0)*mpf(P0))/mpf(Pw)\n",
    "            Py1 = (mpf(Pw1)*mpf(P1))/mpf(Pw)\n",
    "            py0 = mpf(Py0)/(mpf(Py0) + mpf(Py1))\n",
    "            py1 = mpf(Py1)/(mpf(Py0) + mpf(Py1))\n",
    "            \n",
    "            #prediction \n",
    "            if py0>py1:\n",
    "                ypred = float(0)\n",
    "            elif py1>=py0:\n",
    "                ypred = float(1)\n",
    "            if ypred == ytrue:\n",
    "                count = count + 1\n",
    "\n",
    "        accuracy = (count/len(data_tes))*100\n",
    "        stringi = \"test\" + str(i)\n",
    "        nb_accuracy[stringi] = accuracy\n",
    "    #returns accuracy for training and test data \n",
    "    return [tr_acc, nb_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Division by zero\n",
      "For alpha = 0.1 the accuracies :\n",
      "Training data :\n",
      "train0     99.23442757165044\n",
      "train1     98.9721671431123\n",
      "train2     99.3878852251081\n",
      "train3     99.14699231793747\n",
      "train4     99.12758996481284\n",
      "train5     99.17425534403365\n",
      "train6     98.76456876456876\n",
      "Testing data :\n",
      "test0      79.72027972027972\n",
      "test1      83.21678321678321\n",
      "test2      79.72027972027972\n",
      "test3      78.32167832167832\n",
      "test4      77.62237762237763\n",
      "test5      78.32167832167832\n",
      "test6      79.5774647887324\n",
      "Avg training accuracy :  99.11541233303193\n",
      "Avg test accuracy :  79.50007738740133\n",
      "\n",
      "\n",
      "For alpha = 0.2 the accuracies :\n",
      "Training data :\n",
      "train0     99.1430846477521\n",
      "train1     98.92940943407689\n",
      "train2     99.04984455451199\n",
      "train3     99.14699231793747\n",
      "train4     99.10814227908743\n",
      "train5     99.17425534403365\n",
      "train6     98.57614607614607\n",
      "Testing data :\n",
      "test0      80.41958041958041\n",
      "test1      83.21678321678321\n",
      "test2      79.02097902097903\n",
      "test3      79.02097902097903\n",
      "test4      78.32167832167832\n",
      "test5      79.02097902097903\n",
      "test6      78.16901408450704\n",
      "Avg training accuracy :  99.01826780764938\n",
      "Avg test accuracy :  79.59857044364087\n",
      "\n",
      "\n",
      "For alpha = 0.3 the accuracies :\n",
      "Training data :\n",
      "train0     98.85751419590395\n",
      "train1     98.52918603502035\n",
      "train2     98.97794931633905\n",
      "train3     98.6205062926183\n",
      "train4     99.03624704091449\n",
      "train5     98.89448973171261\n",
      "train6     98.29059829059828\n",
      "Testing data :\n",
      "test0      80.41958041958041\n",
      "test1      82.51748251748252\n",
      "test2      79.02097902097903\n",
      "test3      79.02097902097903\n",
      "test4      79.72027972027972\n",
      "test5      78.32167832167832\n",
      "test6      78.16901408450704\n",
      "Avg training accuracy :  98.74378441472957\n",
      "Avg test accuracy :  79.59857044364087\n",
      "\n",
      "\n",
      "For alpha = 0.4 the accuracies :\n",
      "Training data :\n",
      "train0     98.85751419590395\n",
      "train1     98.41844075799736\n",
      "train2     98.97794931633905\n",
      "train3     98.6205062926183\n",
      "train4     98.75257375840806\n",
      "train5     98.26114343325544\n",
      "train6     97.67676767676768\n",
      "Testing data :\n",
      "test0      81.11888111888112\n",
      "test1      81.11888111888112\n",
      "test2      79.02097902097903\n",
      "test3      79.02097902097903\n",
      "test4      79.72027972027972\n",
      "test5      78.32167832167832\n",
      "test6      76.76056338028168\n",
      "Avg training accuracy :  98.50927077589856\n",
      "Avg test accuracy :  79.29746310028001\n",
      "\n",
      "\n",
      "For alpha = 0.5 the accuracies :\n",
      "Training data :\n",
      "train0     98.85751419590395\n",
      "train1     97.8045421452656\n",
      "train2     98.34650018722364\n",
      "train3     97.97351714796288\n",
      "train4     98.73312607268268\n",
      "train5     98.24169574753006\n",
      "train6     97.28049728049729\n",
      "Testing data :\n",
      "test0      81.81818181818183\n",
      "test1      82.51748251748252\n",
      "test2      78.32167832167832\n",
      "test3      79.72027972027972\n",
      "test4      79.72027972027972\n",
      "test5      78.32167832167832\n",
      "test6      76.76056338028168\n",
      "Avg training accuracy :  98.17677039672374\n",
      "Avg test accuracy :  79.59716339998032\n",
      "\n",
      "\n",
      "For alpha = 0.6 the accuracies :\n",
      "Training data :\n",
      "train0     98.78561895773099\n",
      "train1     97.51897169341743\n",
      "train2     97.89190940007744\n",
      "train3     97.93075943892747\n",
      "train4     98.23577757650104\n",
      "train5     98.19893803849463\n",
      "train6     97.23776223776224\n",
      "Testing data :\n",
      "test0      81.81818181818183\n",
      "test1      82.51748251748252\n",
      "test2      79.02097902097903\n",
      "test3      81.11888111888112\n",
      "test4      78.32167832167832\n",
      "test5      79.02097902097903\n",
      "test6      77.46478873239437\n",
      "Avg training accuracy :  97.97139104898733\n",
      "Avg test accuracy :  79.8975672215109\n",
      "\n",
      "\n",
      "For alpha = 0.7 the accuracies :\n",
      "Training data :\n",
      "train0     98.57384091339752\n",
      "train1     97.330503672394\n",
      "train2     97.74226875160365\n",
      "train3     97.82001416190447\n",
      "train4     97.99093166654427\n",
      "train5     97.9191724261736\n",
      "train6     97.06876456876456\n",
      "Testing data :\n",
      "test0      81.81818181818183\n",
      "test1      83.91608391608392\n",
      "test2      78.32167832167832\n",
      "test3      81.11888111888112\n",
      "test4      76.92307692307693\n",
      "test5      79.02097902097903\n",
      "test6      77.46478873239437\n",
      "Avg training accuracy :  97.77792802296888\n",
      "Avg test accuracy :  79.79766712161079\n",
      "\n",
      "\n",
      "For alpha = 0.8 the accuracies :\n",
      "Training data :\n",
      "train0     98.74286124869555\n",
      "train1     97.23916074849565\n",
      "train2     97.69951104256823\n",
      "train3     97.46252580558298\n",
      "train4     97.10112977907609\n",
      "train5     98.18529519229635\n",
      "train6     96.60062160062161\n",
      "Testing data :\n",
      "test0      81.81818181818183\n",
      "test1      83.91608391608392\n",
      "test2      76.22377622377621\n",
      "test3      81.11888111888112\n",
      "test4      76.92307692307693\n",
      "test5      78.32167832167832\n",
      "test6      76.76056338028168\n",
      "Avg training accuracy :  97.57587220247663\n",
      "Avg test accuracy :  79.29746310028\n",
      "\n",
      "\n",
      "For alpha = 0.9 the accuracies :\n",
      "Training data :\n",
      "train0     98.74286124869555\n",
      "train1     96.93414261092208\n",
      "train2     97.34204535254709\n",
      "train3     97.39063056741003\n",
      "train4     97.03892438431528\n",
      "train5     97.6588091669772\n",
      "train6     96.60062160062161\n",
      "Testing data :\n",
      "test0      81.11888111888112\n",
      "test1      83.91608391608392\n",
      "test2      74.12587412587412\n",
      "test3      82.51748251748252\n",
      "test4      77.62237762237763\n",
      "test5      79.02097902097903\n",
      "test6      76.76056338028168\n",
      "Avg training accuracy :  97.38686213306983\n",
      "Avg test accuracy :  79.29746310028\n",
      "\n",
      "\n",
      "For alpha = 1.0 the accuracies :\n",
      "Training data :\n",
      "train0     98.57384091339752\n",
      "train1     96.84279968702373\n",
      "train2     97.25070242864875\n",
      "train3     97.39063056741003\n",
      "train4     96.90873142156688\n",
      "train5     97.58691392880424\n",
      "train6     96.60062160062161\n",
      "Testing data :\n",
      "test0      81.11888111888112\n",
      "test1      83.91608391608392\n",
      "test2      74.12587412587412\n",
      "test3      83.21678321678321\n",
      "test4      77.62237762237763\n",
      "test5      79.02097902097903\n",
      "test6      76.76056338028168\n",
      "Avg training accuracy :  97.30774864963897\n",
      "Avg test accuracy :  79.3973632001801\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# alphas = [0.8]\n",
    "# alphas = [0.2,0.4,0.6,1.0]\n",
    "accuracies_alpha = []\n",
    "accuraciestr_alpha = []\n",
    "accuracies = []\n",
    "accuraciestr = []\n",
    "for alpha in alphas:\n",
    "    maxx = 0.0\n",
    "    maxxtr = 0.0\n",
    "    try:\n",
    "        lisa = k_val_fit(data_np, 7, alpha)\n",
    "        \n",
    "        print(\"For alpha = {} the accuracies :\".format(alpha))\n",
    "        print(\"Training data :\")\n",
    "        for key, value in lisa[0].items(): \n",
    "            k = key\n",
    "            a = value \n",
    "            print (\"{:<10} {:<10}\".format(k, a))\n",
    "        print(\"Testing data :\")\n",
    "        for key, value in lisa[1].items(): \n",
    "            k = key\n",
    "            a = value \n",
    "            print (\"{:<10} {:<10}\".format(k, a)) \n",
    "        \n",
    "        train_avg = sum(lisa[0].values()) / len(lisa[0]) \n",
    "        test_avg = sum(lisa[1].values()) / len(lisa[1])\n",
    "        \n",
    "        print(\"Avg training accuracy : \",train_avg)\n",
    "        print(\"Avg test accuracy : \",test_avg)\n",
    "        print('\\n')\n",
    "        \n",
    "        #finding the max probability in each fold\n",
    "        nbtr_accu = lisa[0]\n",
    "        nb_accu = lisa[1]\n",
    "        for key in nb_accu.keys():\n",
    "            if nb_accu[key]>maxx:\n",
    "                maxx = nb_accu[key]\n",
    "        accuracies_alpha.append([key, alpha, maxx])\n",
    "        accuracies.append(maxx)\n",
    "        for key in nbtr_accu.keys():\n",
    "            if nbtr_accu[key]>maxxtr:\n",
    "                maxxtr = nbtr_accu[key]\n",
    "        accuraciestr_alpha.append([key, alpha, maxxtr])\n",
    "        accuraciestr.append(maxxtr)\n",
    "        #exception for when alpha is 0\n",
    "    except ZeroDivisionError as e:\n",
    "        accuracies_alpha.append([alpha, maxx])\n",
    "        accuracies.append(maxx)\n",
    "        accuraciestr_alpha.append([alpha, maxxtr])\n",
    "        accuraciestr.append(maxxtr)\n",
    "        print(\"Division by zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy in testdata for every alpha :\n",
      "[0.0, 0.0]\n",
      "['test6', 0.1, 83.21678321678321]\n",
      "['test6', 0.2, 83.21678321678321]\n",
      "['test6', 0.3, 82.51748251748252]\n",
      "['test6', 0.4, 81.11888111888112]\n",
      "['test6', 0.5, 82.51748251748252]\n",
      "['test6', 0.6, 82.51748251748252]\n",
      "['test6', 0.7, 83.91608391608392]\n",
      "['test6', 0.8, 83.91608391608392]\n",
      "['test6', 0.9, 83.91608391608392]\n",
      "['test6', 1.0, 83.91608391608392]\n"
     ]
    }
   ],
   "source": [
    "#print maximum accuracy in testdata for each alpha\n",
    "print(\"Max accuracy in testdata for every alpha :\")\n",
    "for i in range(len(accuracies_alpha)):\n",
    "    print(accuracies_alpha[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy in traindata for every alpha :\n",
      "[0.0, 0.0]\n",
      "['train6', 0.1, 99.3878852251081]\n",
      "['train6', 0.2, 99.17425534403365]\n",
      "['train6', 0.3, 99.03624704091449]\n",
      "['train6', 0.4, 98.97794931633905]\n",
      "['train6', 0.5, 98.85751419590395]\n",
      "['train6', 0.6, 98.78561895773099]\n",
      "['train6', 0.7, 98.57384091339752]\n",
      "['train6', 0.8, 98.74286124869555]\n",
      "['train6', 0.9, 98.74286124869555]\n",
      "['train6', 1.0, 98.57384091339752]\n"
     ]
    }
   ],
   "source": [
    "#print maximum accuracy in traindata for each alpha\n",
    "print(\"Max accuracy in traindata for every alpha :\")\n",
    "for i in range(len(accuraciestr_alpha)):\n",
    "    print(accuraciestr_alpha[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting accuracy vs alpha\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "plt.plot(alphas, accuracies, c = \"b\", alpha = 0.3)\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Accuracies for varying Laplace Smoothing parameter\")\n",
    "plt.grid()\n",
    "for i, accu in enumerate(accuracies):\n",
    "    plt.annotate(round(accu, 2), (alphas[i], accuracies[i]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
